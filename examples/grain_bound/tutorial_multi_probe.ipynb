{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import scipy\n",
    "import combo\n",
    "import os\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download():\n",
    "    if not os.path.exists('data/s5-210.csv'):\n",
    "\n",
    "        if not os.path.exists('data'):\n",
    "            os.mkdir('data')\n",
    "        \n",
    "        urllib.urlretrieve('http://www.tsudalab.org/files/s5-210.csv', 'data/s5-210.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    download()\n",
    "    A =  np.asarray( np.loadtxt('data/s5-210.csv',skiprows=1,delimiter=',') )\n",
    "    X = A[:,0:3]\n",
    "    t  = -A[:,3]\n",
    "    return X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data  \n",
    "# X is the N x d dimensional matrix. Each row of X denotes the d-dimensional feature vector of search candidate. \n",
    "# t is the N-dimensional vector that represents the corresponding negative energy of search candidates. \n",
    "# ( It is of course unknown in practice. )\n",
    "X, t = load_data()\n",
    " \n",
    "# Normalize the mean and standard deviation along the each column of X to 0 and 1, respectively\n",
    "X = combo.misc.centering( X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare the class for calling the simulator. \n",
    "# In this tutorial, we simply refer to the value of t. \n",
    "# If you want to apply combo to other problems, you have to customize this class. \n",
    "class simulator:\n",
    "    def __init__( self ):\n",
    "        _, self.t = load_data()\n",
    "    \n",
    "    def __call__( self, action ):\n",
    "        return self.t[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the generative model of GPs. \n",
    "# In Combo, to use the GP inference, we have to define three elements: \n",
    "# kernel, mean of GP prior and likelihood. \n",
    "\n",
    "## Define the kernel \n",
    "## The ordinary Gaussian kernel is defined by \n",
    "cov = combo.gp.cov.gauss( X.shape[1], ard = False )\n",
    "\n",
    "## If you want to use the Gaussian ARD kernel, set 'ard' to 'True'\n",
    "## cov = combo.gp.cov.gauss(X.shape[1], ard = True )\n",
    "\n",
    "## Define the mean of GP prior\n",
    "## To employ the constant value as the mean of GP prior, write as below: \n",
    "mean = combo.gp.mean.const()\n",
    "## Also, define the zero mean, i.e., always takes zero as \n",
    "# mean = combo.gp.mean.zero()\n",
    "\n",
    "## Define the likelihood \n",
    "## define isotoropic Gaussian likelihood as bellow:\n",
    "lik = combo.gp.lik.gauss()\n",
    "\n",
    "# Finally, declare the generative model of Gaussian process as \n",
    "gp = combo.gp.model(lik=lik, mean = mean, cov = cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( search )\n",
      "dir_name: res\n",
      "num_multi_probe:  10\n",
      "multi_probe_num_sampling:  20\n",
      "score: EI\n",
      "max_search: 100\n",
      "num_rand_search:  20\n",
      "alpha:  0.5\n",
      "\n",
      "\n",
      "( predict )\n",
      "is_rand_expans:  False\n",
      "num_basis:  5000\n",
      "\n",
      "\n",
      "( learning )\n",
      "method :  adam\n",
      "is_hyparams_learning:  True\n",
      "is_disp:  True\n",
      "num_init_params_search:  20\n",
      "interval:  20\n",
      "max_epoch:  500\n",
      "max_epoch_init_params_search:  30\n",
      "batch_size:  64\n",
      "eval_size:  5000\n",
      "alpha =  0.001\n",
      "beta =  0.9\n",
      "gamma =  0.999\n",
      "epsilon =  1e-06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set the configure for COMBO\n",
    "# To modify the configure of COMBO,  you have to edit the configure files. \n",
    "# Please check 'config.ini' if you want to know how to write the configure file \n",
    "# loading the configure files, write as follows:\n",
    "config = combo.misc.set_config()\n",
    "config.load('multi_probe_config.ini')\n",
    "config.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001-th step: f(x) = -1.037109, max_f(x) = -1.037109 \n",
      "\n",
      "002-th step: f(x) = -1.040397, max_f(x) = -1.037109 \n",
      "\n",
      "003-th step: f(x) = -0.995182, max_f(x) = -0.995182 \n",
      "\n",
      "004-th step: f(x) = -1.120972, max_f(x) = -0.995182 \n",
      "\n",
      "005-th step: f(x) = -1.092801, max_f(x) = -0.995182 \n",
      "\n",
      "006-th step: f(x) = -1.104426, max_f(x) = -0.995182 \n",
      "\n",
      "007-th step: f(x) = -1.082187, max_f(x) = -0.995182 \n",
      "\n",
      "008-th step: f(x) = -1.145944, max_f(x) = -0.995182 \n",
      "\n",
      "009-th step: f(x) = -1.069718, max_f(x) = -0.995182 \n",
      "\n",
      "010-th step: f(x) = -1.046275, max_f(x) = -0.995182 \n",
      "\n",
      "011-th step: f(x) = -1.035465, max_f(x) = -0.995182 \n",
      "\n",
      "012-th step: f(x) = -1.095248, max_f(x) = -0.995182 \n",
      "\n",
      "013-th step: f(x) = -1.188696, max_f(x) = -0.995182 \n",
      "\n",
      "014-th step: f(x) = -1.055151, max_f(x) = -0.995182 \n",
      "\n",
      "015-th step: f(x) = -1.122468, max_f(x) = -0.995182 \n",
      "\n",
      "016-th step: f(x) = -0.966407, max_f(x) = -0.966407 \n",
      "\n",
      "017-th step: f(x) = -1.013328, max_f(x) = -0.966407 \n",
      "\n",
      "018-th step: f(x) = -1.137878, max_f(x) = -0.966407 \n",
      "\n",
      "019-th step: f(x) = -1.004440, max_f(x) = -0.966407 \n",
      "\n",
      "020-th step: f(x) = -1.021882, max_f(x) = -0.966407 \n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood -13.28949271\n",
      "50 -th epoch marginal likelihood -17.4271409165\n",
      "100 -th epoch marginal likelihood -20.0574288743\n",
      "150 -th epoch marginal likelihood -21.7610291082\n",
      "200 -th epoch marginal likelihood -22.9028465187\n",
      "250 -th epoch marginal likelihood -23.6907554303\n",
      "300 -th epoch marginal likelihood -24.2493311422\n",
      "350 -th epoch marginal likelihood -24.6564184763\n",
      "400 -th epoch marginal likelihood -24.9622214614\n",
      "450 -th epoch marginal likelihood -25.1998712525\n",
      "500 -th epoch marginal likelihood -25.3915747256\n",
      "Done\n",
      "\n",
      "00-th multiple probe search\n",
      "021-th step: f(x) = -1.030329, max_f(x) = -0.966407 \n",
      "\n",
      "022-th step: f(x) = -0.977343, max_f(x) = -0.966407 \n",
      "\n",
      "023-th step: f(x) = -1.001885, max_f(x) = -0.966407 \n",
      "\n",
      "024-th step: f(x) = -0.973811, max_f(x) = -0.966407 \n",
      "\n",
      "025-th step: f(x) = -1.099617, max_f(x) = -0.966407 \n",
      "\n",
      "026-th step: f(x) = -0.970183, max_f(x) = -0.966407 \n",
      "\n",
      "027-th step: f(x) = -1.021818, max_f(x) = -0.966407 \n",
      "\n",
      "028-th step: f(x) = -1.015254, max_f(x) = -0.966407 \n",
      "\n",
      "029-th step: f(x) = -0.969436, max_f(x) = -0.966407 \n",
      "\n",
      "030-th step: f(x) = -0.993661, max_f(x) = -0.966407 \n",
      "\n",
      "01-th multiple probe search\n",
      "031-th step: f(x) = -2.832830, max_f(x) = -0.966407 \n",
      "\n",
      "032-th step: f(x) = -0.994621, max_f(x) = -0.966407 \n",
      "\n",
      "033-th step: f(x) = -1.017941, max_f(x) = -0.966407 \n",
      "\n",
      "034-th step: f(x) = -1.077711, max_f(x) = -0.966407 \n",
      "\n",
      "035-th step: f(x) = -1.034649, max_f(x) = -0.966407 \n",
      "\n",
      "036-th step: f(x) = -1.012647, max_f(x) = -0.966407 \n",
      "\n",
      "037-th step: f(x) = -1.047001, max_f(x) = -0.966407 \n",
      "\n",
      "038-th step: f(x) = -1.024663, max_f(x) = -0.966407 \n",
      "\n",
      "039-th step: f(x) = -1.004979, max_f(x) = -0.966407 \n",
      "\n",
      "040-th step: f(x) = -0.995187, max_f(x) = -0.966407 \n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood 867.422121524\n",
      "50 -th epoch marginal likelihood 768.943073596\n",
      "100 -th epoch marginal likelihood 687.215869112\n",
      "150 -th epoch marginal likelihood 618.697520261\n",
      "200 -th epoch marginal likelihood 560.282573504\n",
      "250 -th epoch marginal likelihood 509.757359142\n",
      "300 -th epoch marginal likelihood 465.481053338\n",
      "350 -th epoch marginal likelihood 426.168662457\n",
      "400 -th epoch marginal likelihood 390.756105416\n",
      "450 -th epoch marginal likelihood 358.309097036\n",
      "500 -th epoch marginal likelihood 327.964403438\n",
      "Done\n",
      "\n",
      "02-th multiple probe search\n",
      "041-th step: f(x) = -0.957479, max_f(x) = -0.957479 \n",
      "\n",
      "042-th step: f(x) = -0.984545, max_f(x) = -0.957479 \n",
      "\n",
      "043-th step: f(x) = -1.276674, max_f(x) = -0.957479 \n",
      "\n",
      "044-th step: f(x) = -0.958246, max_f(x) = -0.957479 \n",
      "\n",
      "045-th step: f(x) = -1.045459, max_f(x) = -0.957479 \n",
      "\n",
      "046-th step: f(x) = -1.227426, max_f(x) = -0.957479 \n",
      "\n",
      "047-th step: f(x) = -0.993966, max_f(x) = -0.957479 \n",
      "\n",
      "048-th step: f(x) = -1.068930, max_f(x) = -0.957479 \n",
      "\n",
      "049-th step: f(x) = -1.025987, max_f(x) = -0.957479 \n",
      "\n",
      "050-th step: f(x) = -1.189012, max_f(x) = -0.957479 \n",
      "\n",
      "03-th multiple probe search\n",
      "051-th step: f(x) = -0.957468, max_f(x) = -0.957468 \n",
      "\n",
      "052-th step: f(x) = -0.961411, max_f(x) = -0.957468 \n",
      "\n",
      "053-th step: f(x) = -1.053579, max_f(x) = -0.957468 \n",
      "\n",
      "054-th step: f(x) = -2.621007, max_f(x) = -0.957468 \n",
      "\n",
      "055-th step: f(x) = -1.132242, max_f(x) = -0.957468 \n",
      "\n",
      "056-th step: f(x) = -1.005624, max_f(x) = -0.957468 \n",
      "\n",
      "057-th step: f(x) = -1.050690, max_f(x) = -0.957468 \n",
      "\n",
      "058-th step: f(x) = -1.041715, max_f(x) = -0.957468 \n",
      "\n",
      "059-th step: f(x) = -1.033097, max_f(x) = -0.957468 \n",
      "\n",
      "060-th step: f(x) = -1.113365, max_f(x) = -0.957468 \n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood 837.196405726\n",
      "50 -th epoch marginal likelihood 725.558137016\n",
      "100 -th epoch marginal likelihood 637.529006239\n",
      "150 -th epoch marginal likelihood 567.665693855\n",
      "200 -th epoch marginal likelihood 511.076604082\n",
      "250 -th epoch marginal likelihood 464.299949574\n",
      "300 -th epoch marginal likelihood 424.922798971\n",
      "350 -th epoch marginal likelihood 391.25430799\n",
      "400 -th epoch marginal likelihood 362.091280619\n",
      "450 -th epoch marginal likelihood 336.558726348\n",
      "500 -th epoch marginal likelihood 314.00450023\n",
      "Done\n",
      "\n",
      "04-th multiple probe search\n",
      "061-th step: f(x) = -1.014565, max_f(x) = -0.957468 \n",
      "\n",
      "062-th step: f(x) = -0.993769, max_f(x) = -0.957468 \n",
      "\n",
      "063-th step: f(x) = -1.032050, max_f(x) = -0.957468 \n",
      "\n",
      "064-th step: f(x) = -1.010369, max_f(x) = -0.957468 \n",
      "\n",
      "065-th step: f(x) = -1.021385, max_f(x) = -0.957468 \n",
      "\n",
      "066-th step: f(x) = -0.974955, max_f(x) = -0.957468 \n",
      "\n",
      "067-th step: f(x) = -1.024102, max_f(x) = -0.957468 \n",
      "\n",
      "068-th step: f(x) = -1.034706, max_f(x) = -0.957468 \n",
      "\n",
      "069-th step: f(x) = -1.006337, max_f(x) = -0.957468 \n",
      "\n",
      "070-th step: f(x) = -1.025482, max_f(x) = -0.957468 \n",
      "\n",
      "05-th multiple probe search\n",
      "071-th step: f(x) = -0.992155, max_f(x) = -0.957468 \n",
      "\n",
      "072-th step: f(x) = -1.073820, max_f(x) = -0.957468 \n",
      "\n",
      "073-th step: f(x) = -0.977220, max_f(x) = -0.957468 \n",
      "\n",
      "074-th step: f(x) = -1.163325, max_f(x) = -0.957468 \n",
      "\n",
      "075-th step: f(x) = -1.046507, max_f(x) = -0.957468 \n",
      "\n",
      "076-th step: f(x) = -1.105745, max_f(x) = -0.957468 \n",
      "\n",
      "077-th step: f(x) = -1.280940, max_f(x) = -0.957468 \n",
      "\n",
      "078-th step: f(x) = -1.118484, max_f(x) = -0.957468 \n",
      "\n",
      "079-th step: f(x) = -1.015880, max_f(x) = -0.957468 \n",
      "\n",
      "080-th step: f(x) = -1.062362, max_f(x) = -0.957468 \n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood 1256.50327688\n",
      "50 -th epoch marginal likelihood 1120.90424131\n",
      "100 -th epoch marginal likelihood 986.744910591\n",
      "150 -th epoch marginal likelihood 873.19705795\n",
      "200 -th epoch marginal likelihood 787.732295733\n",
      "250 -th epoch marginal likelihood 713.057289122\n",
      "300 -th epoch marginal likelihood 651.347382512\n",
      "350 -th epoch marginal likelihood 602.233907902\n",
      "400 -th epoch marginal likelihood 557.193776194\n",
      "450 -th epoch marginal likelihood 518.759197238\n",
      "500 -th epoch marginal likelihood 481.936526974\n",
      "Done\n",
      "\n",
      "06-th multiple probe search\n",
      "081-th step: f(x) = -0.965441, max_f(x) = -0.957468 \n",
      "\n",
      "082-th step: f(x) = -1.019266, max_f(x) = -0.957468 \n",
      "\n",
      "083-th step: f(x) = -0.965245, max_f(x) = -0.957468 \n",
      "\n",
      "084-th step: f(x) = -1.017363, max_f(x) = -0.957468 \n",
      "\n",
      "085-th step: f(x) = -1.114651, max_f(x) = -0.957468 \n",
      "\n",
      "086-th step: f(x) = -1.155720, max_f(x) = -0.957468 \n",
      "\n",
      "087-th step: f(x) = -1.087675, max_f(x) = -0.957468 \n",
      "\n",
      "088-th step: f(x) = -1.003275, max_f(x) = -0.957468 \n",
      "\n",
      "089-th step: f(x) = -1.046464, max_f(x) = -0.957468 \n",
      "\n",
      "090-th step: f(x) = -0.990656, max_f(x) = -0.957468 \n",
      "\n",
      "07-th multiple probe search\n",
      "091-th step: f(x) = -1.012534, max_f(x) = -0.957468 \n",
      "\n",
      "092-th step: f(x) = -0.998130, max_f(x) = -0.957468 \n",
      "\n",
      "093-th step: f(x) = -1.050308, max_f(x) = -0.957468 \n",
      "\n",
      "094-th step: f(x) = -0.964398, max_f(x) = -0.957468 \n",
      "\n",
      "095-th step: f(x) = -1.094078, max_f(x) = -0.957468 \n",
      "\n",
      "096-th step: f(x) = -1.008063, max_f(x) = -0.957468 \n",
      "\n",
      "097-th step: f(x) = -1.195896, max_f(x) = -0.957468 \n",
      "\n",
      "098-th step: f(x) = -0.993507, max_f(x) = -0.957468 \n",
      "\n",
      "099-th step: f(x) = -0.969744, max_f(x) = -0.957468 \n",
      "\n",
      "100-th step: f(x) = -1.027737, max_f(x) = -0.957468 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# design of policy\n",
    "\n",
    "# Declaring the multi probe version of bayesian policy is performed by \n",
    "search = combo.search.multi_probe_policy( simulator(), X, config)\n",
    "\n",
    "# if you want to use the random policy as baseline, define in the same manner: \n",
    "#search = combo.search.random_policy(simulator(), X, config)\n",
    "\n",
    "# set the seed parameter \n",
    "search.set_seed( 0 )\n",
    "\n",
    "# Execute the bayes search.  \n",
    "# The file_name determines the name of output file which is generated after the search process. \n",
    "# If not defining, the file_name automatically become 'bayes_search_00x.dump', where x is the seed.  \n",
    "search.run( gp, file_name='multi_probe_EI' )\n",
    "\n",
    "# If you already have the training data ( train_X, train_t ), you can use it \n",
    "# search.run( gp , train_X = train_X, train_t = train_t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.95744971599999995"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
