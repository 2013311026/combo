{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import scipy\n",
    "import combo\n",
    "import os\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download():\n",
    "    if not os.path.exists('data/s5-210.csv'):\n",
    "\n",
    "        if not os.path.exists('data'):\n",
    "            os.mkdir('data')\n",
    "            \n",
    "        print('Downloading...')\n",
    "        urllib.urlretrieve('http://www.tsudalab.org/files/s5-210.csv', 'data/s5-210.csv')\n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    download()\n",
    "    A =  np.asarray( np.loadtxt('data/s5-210.csv',skiprows=1,delimiter=',') )\n",
    "    X = A[:,0:3]\n",
    "    t  = -A[:,3]\n",
    "    return X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data. \n",
    "# X is the N x d dimensional matrix. Each row of X denotes the d-dimensional feature vector of search candidate. \n",
    "# t is the N-dimensional vector that represents the corresponding negative energy of search candidates. \n",
    "# ( It is of course unknown in practice. )\n",
    "X, t = load_data()\n",
    " \n",
    "# Normalize the mean and standard deviation along the each column of X to 0 and 1, respectively\n",
    "X = combo.misc.centering( X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Declare the class for calling the simulator. \n",
    "# In this tutorial, we simply refer to the value of t. \n",
    "# If you want to apply combo to other problems, you have to customize this class. \n",
    "class simulator:\n",
    "    def __init__( self ):\n",
    "        _, self.t = load_data()\n",
    "    \n",
    "    def __call__( self, action ):\n",
    "        return self.t[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the generative model of GPs. \n",
    "# In Combo, to use the GP inference, we have to define three elements: \n",
    "# kernel, mean of GP prior and likelihood. \n",
    "\n",
    "## Define the kernel \n",
    "## The ordinary Gaussian kernel is defined by \n",
    "cov = combo.gp.cov.gauss( X.shape[1], ard = False )\n",
    "\n",
    "## If you want to use the Gaussian ARD kernel, set 'ard' to 'True'\n",
    "## cov = combo.gp.cov.gauss(X.shape[1], ard = True )\n",
    "\n",
    "## Define the mean of GP prior\n",
    "## To employ the constant value as the mean of GP prior, write as below: \n",
    "mean = combo.gp.mean.const()\n",
    "## Also, define the zero mean, i.e., always takes zero as \n",
    "# mean = combo.gp.mean.zero()\n",
    "\n",
    "## Define the likelihood \n",
    "## define isotoropic Gaussian likelihood as bellow:\n",
    "lik = combo.gp.lik.gauss()\n",
    "\n",
    "# Finally, declare the generative model of Gaussian process as \n",
    "gp = combo.gp.model(lik=lik, mean = mean, cov = cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( search )\n",
      "dir_name: res\n",
      "score: TS\n",
      "max_search: 100\n",
      "num_rand_search:  20\n",
      "alpha:  1.0\n",
      "\n",
      "\n",
      "( predict )\n",
      "is_rand_expans:  True\n",
      "num_basis:  5000\n",
      "\n",
      "\n",
      "( learning )\n",
      "method :  adam\n",
      "is_hyparams_learning:  True\n",
      "is_disp:  False\n",
      "num_init_params_search:  20\n",
      "interval:  20\n",
      "max_epoch:  2000\n",
      "max_epoch_init_params_search:  20\n",
      "batch_size:  64\n",
      "eval_size:  5000\n",
      "alpha =  0.001\n",
      "beta =  0.9\n",
      "gamma =  0.999\n",
      "epsilon =  1e-06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set the configure for COMBO\n",
    "# To modify the configure of COMBO,  you have to edit the configure files. \n",
    "# Please check 'config.ini' if you want to know how to write the configure file\n",
    "# loading the configure files, write as follows:\n",
    "config = combo.misc.set_config()\n",
    "config.load('config.ini')\n",
    "config.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the random search .....\n",
      "\n",
      "001-th step: f(x) = -1.037109, max_f(x) = -1.037109 \n",
      "\n",
      "002-th step: f(x) = -1.040397, max_f(x) = -1.037109 \n",
      "\n",
      "003-th step: f(x) = -0.995182, max_f(x) = -0.995182 \n",
      "\n",
      "004-th step: f(x) = -1.120972, max_f(x) = -0.995182 \n",
      "\n",
      "005-th step: f(x) = -1.092801, max_f(x) = -0.995182 \n",
      "\n",
      "006-th step: f(x) = -1.104426, max_f(x) = -0.995182 \n",
      "\n",
      "007-th step: f(x) = -1.082187, max_f(x) = -0.995182 \n",
      "\n",
      "008-th step: f(x) = -1.145944, max_f(x) = -0.995182 \n",
      "\n",
      "009-th step: f(x) = -1.069718, max_f(x) = -0.995182 \n",
      "\n",
      "010-th step: f(x) = -1.046275, max_f(x) = -0.995182 \n",
      "\n",
      "011-th step: f(x) = -1.035465, max_f(x) = -0.995182 \n",
      "\n",
      "012-th step: f(x) = -1.095248, max_f(x) = -0.995182 \n",
      "\n",
      "013-th step: f(x) = -1.188696, max_f(x) = -0.995182 \n",
      "\n",
      "014-th step: f(x) = -1.055151, max_f(x) = -0.995182 \n",
      "\n",
      "015-th step: f(x) = -1.122468, max_f(x) = -0.995182 \n",
      "\n",
      "016-th step: f(x) = -0.966407, max_f(x) = -0.966407 \n",
      "\n",
      "017-th step: f(x) = -1.013328, max_f(x) = -0.966407 \n",
      "\n",
      "018-th step: f(x) = -1.137878, max_f(x) = -0.966407 \n",
      "\n",
      "019-th step: f(x) = -1.004440, max_f(x) = -0.966407 \n",
      "\n",
      "020-th step: f(x) = -1.021882, max_f(x) = -0.966407 \n",
      "\n",
      "Done.\n",
      " \n",
      "Start the bayes search ....\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "Done\n",
      "\n",
      "021-th step: f(x) = -0.986340, max_f(x) = -0.966407 \n",
      "\n",
      "022-th step: f(x) = -1.079103, max_f(x) = -0.966407 \n",
      "\n",
      "023-th step: f(x) = -1.073015, max_f(x) = -0.966407 \n",
      "\n",
      "024-th step: f(x) = -0.993097, max_f(x) = -0.966407 \n",
      "\n",
      "025-th step: f(x) = -0.985868, max_f(x) = -0.966407 \n",
      "\n",
      "026-th step: f(x) = -0.998491, max_f(x) = -0.966407 \n",
      "\n",
      "027-th step: f(x) = -0.965811, max_f(x) = -0.965811 \n",
      "\n",
      "028-th step: f(x) = -1.053048, max_f(x) = -0.965811 \n",
      "\n",
      "029-th step: f(x) = -1.025558, max_f(x) = -0.965811 \n",
      "\n",
      "030-th step: f(x) = -1.051171, max_f(x) = -0.965811 \n",
      "\n",
      "031-th step: f(x) = -1.006749, max_f(x) = -0.965811 \n",
      "\n",
      "032-th step: f(x) = -1.047970, max_f(x) = -0.965811 \n",
      "\n",
      "033-th step: f(x) = -0.982995, max_f(x) = -0.965811 \n",
      "\n",
      "034-th step: f(x) = -1.093035, max_f(x) = -0.965811 \n",
      "\n",
      "035-th step: f(x) = -0.975733, max_f(x) = -0.965811 \n",
      "\n",
      "036-th step: f(x) = -1.008400, max_f(x) = -0.965811 \n",
      "\n",
      "037-th step: f(x) = -1.207851, max_f(x) = -0.965811 \n",
      "\n",
      "038-th step: f(x) = -1.022741, max_f(x) = -0.965811 \n",
      "\n",
      "039-th step: f(x) = -0.961516, max_f(x) = -0.961516 \n",
      "\n",
      "040-th step: f(x) = -1.016608, max_f(x) = -0.961516 \n",
      "\n",
      "041-th step: f(x) = -0.992651, max_f(x) = -0.961516 \n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "Done\n",
      "\n",
      "042-th step: f(x) = -1.079597, max_f(x) = -0.961516 \n",
      "\n",
      "043-th step: f(x) = -1.052780, max_f(x) = -0.961516 \n",
      "\n",
      "044-th step: f(x) = -1.205507, max_f(x) = -0.961516 \n",
      "\n",
      "045-th step: f(x) = -1.017111, max_f(x) = -0.961516 \n",
      "\n",
      "046-th step: f(x) = -0.998819, max_f(x) = -0.961516 \n",
      "\n",
      "047-th step: f(x) = -2.972638, max_f(x) = -0.961516 \n",
      "\n",
      "048-th step: f(x) = -0.965956, max_f(x) = -0.961516 \n",
      "\n",
      "049-th step: f(x) = -1.015254, max_f(x) = -0.961516 \n",
      "\n",
      "050-th step: f(x) = -0.966723, max_f(x) = -0.961516 \n",
      "\n",
      "051-th step: f(x) = -0.990406, max_f(x) = -0.961516 \n",
      "\n",
      "052-th step: f(x) = -1.022619, max_f(x) = -0.961516 \n",
      "\n",
      "053-th step: f(x) = -0.976175, max_f(x) = -0.961516 \n",
      "\n",
      "054-th step: f(x) = -1.009077, max_f(x) = -0.961516 \n",
      "\n",
      "055-th step: f(x) = -1.110863, max_f(x) = -0.961516 \n",
      "\n",
      "056-th step: f(x) = -1.013269, max_f(x) = -0.961516 \n",
      "\n",
      "057-th step: f(x) = -1.018095, max_f(x) = -0.961516 \n",
      "\n",
      "058-th step: f(x) = -1.055456, max_f(x) = -0.961516 \n",
      "\n",
      "059-th step: f(x) = -1.015225, max_f(x) = -0.961516 \n",
      "\n",
      "060-th step: f(x) = -1.082958, max_f(x) = -0.961516 \n",
      "\n",
      "061-th step: f(x) = -1.022625, max_f(x) = -0.961516 \n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "Done\n",
      "\n",
      "062-th step: f(x) = -0.957688, max_f(x) = -0.957688 \n",
      "\n",
      "063-th step: f(x) = -1.047419, max_f(x) = -0.957688 \n",
      "\n",
      "064-th step: f(x) = -1.042992, max_f(x) = -0.957688 \n",
      "\n",
      "065-th step: f(x) = -1.113584, max_f(x) = -0.957688 \n",
      "\n",
      "066-th step: f(x) = -1.022219, max_f(x) = -0.957688 \n",
      "\n",
      "067-th step: f(x) = -0.998450, max_f(x) = -0.957688 \n",
      "\n",
      "068-th step: f(x) = -1.169322, max_f(x) = -0.957688 \n",
      "\n",
      "069-th step: f(x) = -1.031592, max_f(x) = -0.957688 \n",
      "\n",
      "070-th step: f(x) = -0.985976, max_f(x) = -0.957688 \n",
      "\n",
      "071-th step: f(x) = -0.963759, max_f(x) = -0.957688 \n",
      "\n",
      "072-th step: f(x) = -1.089183, max_f(x) = -0.957688 \n",
      "\n",
      "073-th step: f(x) = -1.008079, max_f(x) = -0.957688 \n",
      "\n",
      "074-th step: f(x) = -1.073857, max_f(x) = -0.957688 \n",
      "\n",
      "075-th step: f(x) = -1.012299, max_f(x) = -0.957688 \n",
      "\n",
      "076-th step: f(x) = -1.018130, max_f(x) = -0.957688 \n",
      "\n",
      "077-th step: f(x) = -1.050871, max_f(x) = -0.957688 \n",
      "\n",
      "078-th step: f(x) = -1.000563, max_f(x) = -0.957688 \n",
      "\n",
      "079-th step: f(x) = -0.982963, max_f(x) = -0.957688 \n",
      "\n",
      "080-th step: f(x) = -1.069255, max_f(x) = -0.957688 \n",
      "\n",
      "081-th step: f(x) = -1.049625, max_f(x) = -0.957688 \n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "Done\n",
      "\n",
      "082-th step: f(x) = -1.063881, max_f(x) = -0.957688 \n",
      "\n",
      "083-th step: f(x) = -0.993654, max_f(x) = -0.957688 \n",
      "\n",
      "084-th step: f(x) = -1.059585, max_f(x) = -0.957688 \n",
      "\n",
      "085-th step: f(x) = -1.100629, max_f(x) = -0.957688 \n",
      "\n",
      "086-th step: f(x) = -1.061874, max_f(x) = -0.957688 \n",
      "\n",
      "087-th step: f(x) = -1.770352, max_f(x) = -0.957688 \n",
      "\n",
      "088-th step: f(x) = -1.073160, max_f(x) = -0.957688 \n",
      "\n",
      "089-th step: f(x) = -1.004467, max_f(x) = -0.957688 \n",
      "\n",
      "090-th step: f(x) = -1.054011, max_f(x) = -0.957688 \n",
      "\n",
      "091-th step: f(x) = -1.062418, max_f(x) = -0.957688 \n",
      "\n",
      "092-th step: f(x) = -1.081195, max_f(x) = -0.957688 \n",
      "\n",
      "093-th step: f(x) = -1.032407, max_f(x) = -0.957688 \n",
      "\n",
      "094-th step: f(x) = -1.190144, max_f(x) = -0.957688 \n",
      "\n",
      "095-th step: f(x) = -2.544162, max_f(x) = -0.957688 \n",
      "\n",
      "096-th step: f(x) = -1.025695, max_f(x) = -0.957688 \n",
      "\n",
      "097-th step: f(x) = -0.995750, max_f(x) = -0.957688 \n",
      "\n",
      "098-th step: f(x) = -1.022761, max_f(x) = -0.957688 \n",
      "\n",
      "099-th step: f(x) = -1.050830, max_f(x) = -0.957688 \n",
      "\n",
      "100-th step: f(x) = -0.970160, max_f(x) = -0.957688 \n",
      "\n",
      "Done.\n",
      " \n",
      "Save...\n",
      "Done. \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# design of policy\n",
    "\n",
    "# Declaring the bayesian policy is performed by \n",
    "search = combo.search.bayes_policy( simulator(), X, config)\n",
    "\n",
    "# if you want to use the random policy as baseline, define in the same manner: \n",
    "#search = combo.search.random_policy(simulator(), X, config)\n",
    "\n",
    "# set the seed parameter \n",
    "search.set_seed( 0 )\n",
    "\n",
    "# Execute the bayes search.  \n",
    "# The file_name determines the name of output file which is generated after the search process. \n",
    "# If not defining, the file_name automatically become 'bayes_search_00x.dump', where x is the seed.  \n",
    "search.run( gp, file_name='TS' )\n",
    "\n",
    "# If you already have the training data ( train_X, train_t ), you can use it \n",
    "# search.run( gp , train_X = train_X, train_t = train_t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x110227d90>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1044a6e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The result of searching is summarized in the class search.res\n",
    "# res.fx: observed negative energy at each step\n",
    "# res.max_fx: the current maximum value of the negative energy that has been obserbed until each step\n",
    "# res.config: the configure files when search was performed\n",
    "plt.plot(search.res.max_fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load \n",
    "with open('res/TS.dump') as f:\n",
    "        res =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.03710867 -1.04039693 -0.99518235 -1.1209724  -1.09280121 -1.10442594\n",
      " -1.08218651 -1.14594404 -1.06971803 -1.04627468 -1.03546497 -1.09524828\n",
      " -1.18869562 -1.05515129 -1.12246828 -0.96640706 -1.01332817 -1.13787848\n",
      " -1.00444047 -1.02188212 -0.98633985 -1.07910265 -1.07301539 -0.99309688\n",
      " -0.98586795 -0.99849108 -0.96581093 -1.05304791 -1.02555813 -1.0511711\n",
      " -1.00674853 -1.04797012 -0.98299474 -1.09303545 -0.97573312 -1.00840019\n",
      " -1.20785148 -1.02274064 -0.96151604 -1.01660761 -0.99265142 -1.07959673\n",
      " -1.05278041 -1.20550732 -1.01711107 -0.99881942 -2.97263767 -0.9659562\n",
      " -1.01525359 -0.96672261 -0.99040647 -1.02261869 -0.9761746  -1.00907677\n",
      " -1.11086287 -1.01326904 -1.01809524 -1.05545633 -1.01522488 -1.08295833\n",
      " -1.02262466 -0.95768794 -1.04741862 -1.0429924  -1.11358428 -1.02221871\n",
      " -0.99844957 -1.16932229 -1.03159167 -0.98597598 -0.96375929 -1.08918262\n",
      " -1.00807924 -1.07385685 -1.01229851 -1.01812992 -1.05087147 -1.00056347\n",
      " -0.9829629  -1.06925494 -1.04962548 -1.06388065 -0.99365435 -1.05958491\n",
      " -1.1006294  -1.06187421 -1.77035237 -1.07316037 -1.0044669  -1.05401133\n",
      " -1.06241803 -1.08119495 -1.0324067  -1.19014431 -2.54416154 -1.02569459\n",
      " -0.99575006 -1.02276083 -1.05082997 -0.97016011]\n",
      "[-1.03710867 -1.03710867 -0.99518235 -0.99518235 -0.99518235 -0.99518235\n",
      " -0.99518235 -0.99518235 -0.99518235 -0.99518235 -0.99518235 -0.99518235\n",
      " -0.99518235 -0.99518235 -0.99518235 -0.96640706 -0.96640706 -0.96640706\n",
      " -0.96640706 -0.96640706 -0.96640706 -0.96640706 -0.96640706 -0.96640706\n",
      " -0.96640706 -0.96640706 -0.96581093 -0.96581093 -0.96581093 -0.96581093\n",
      " -0.96581093 -0.96581093 -0.96581093 -0.96581093 -0.96581093 -0.96581093\n",
      " -0.96581093 -0.96581093 -0.96151604 -0.96151604 -0.96151604 -0.96151604\n",
      " -0.96151604 -0.96151604 -0.96151604 -0.96151604 -0.96151604 -0.96151604\n",
      " -0.96151604 -0.96151604 -0.96151604 -0.96151604 -0.96151604 -0.96151604\n",
      " -0.96151604 -0.96151604 -0.96151604 -0.96151604 -0.96151604 -0.96151604\n",
      " -0.96151604 -0.95768794 -0.95768794 -0.95768794 -0.95768794 -0.95768794\n",
      " -0.95768794 -0.95768794 -0.95768794 -0.95768794 -0.95768794 -0.95768794\n",
      " -0.95768794 -0.95768794 -0.95768794 -0.95768794 -0.95768794 -0.95768794\n",
      " -0.95768794 -0.95768794 -0.95768794 -0.95768794 -0.95768794 -0.95768794\n",
      " -0.95768794 -0.95768794 -0.95768794 -0.95768794 -0.95768794 -0.95768794\n",
      " -0.95768794 -0.95768794 -0.95768794 -0.95768794 -0.95768794 -0.95768794\n",
      " -0.95768794 -0.95768794 -0.95768794 -0.95768794]\n"
     ]
    }
   ],
   "source": [
    "print res.fx\n",
    "print res.max_fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
