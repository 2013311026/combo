{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import scipy\n",
    "import combo\n",
    "import os\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download():\n",
    "    if not os.path.exists('data/s5-210.csv'):\n",
    "\n",
    "        if not os.path.exists('data'):\n",
    "            os.mkdir('data')\n",
    "        \n",
    "        urllib.urlretrieve('http://www.tsudalab.org/files/s5-210.csv', 'data/s5-210.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    download()\n",
    "    A =  np.asarray( np.loadtxt('data/s5-210.csv',skiprows=1,delimiter=',') )\n",
    "    X = A[:,0:3]\n",
    "    t  = -A[:,3]\n",
    "    return X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data  \n",
    "# X is the N x d dimensional matrix. Each row of X denotes the d-dimensional feature vector of search candidate. \n",
    "# t is the N-dimensional vector that represents the corresponding negative energy of search candidates. \n",
    "# ( It is of course unknown in practice. )\n",
    "X, t = load_data()\n",
    " \n",
    "# Normalize the mean and standard deviation along the each column of X to 0 and 1, respectively\n",
    "X = combo.misc.centering( X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare the class for calling the simulator. \n",
    "# In this tutorial, we simply refer to the value of t. \n",
    "# If you want to apply combo to other problems, you have to customize this class. \n",
    "class simulator:\n",
    "    def __init__( self ):\n",
    "        _, self.t = load_data()\n",
    "    \n",
    "    def __call__( self, action ):\n",
    "        return self.t[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Design of policy\n",
    "\n",
    "# Declaring the policy by \n",
    "policy = combo.search.discrete.policy(test_X=X)\n",
    "# test_X is the set of candidates which is represented by numpy.array.\n",
    "# Each row vector represents the feature vector of the corresponding candidate\n",
    "\n",
    "# set the seed parameter \n",
    "policy.set_seed( 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interactive mode stars ... \n",
      " \n",
      "0001-th multiple probe search (random) \n",
      "\n",
      "0002-th multiple probe search (random) \n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood -22.8397384798\n",
      "50 -th epoch marginal likelihood -24.1776171399\n",
      "100 -th epoch marginal likelihood -24.8310182858\n",
      "150 -th epoch marginal likelihood -25.1541614865\n",
      "200 -th epoch marginal likelihood -25.334465628\n",
      "250 -th epoch marginal likelihood -25.4551550106\n",
      "300 -th epoch marginal likelihood -25.5500914536\n",
      "350 -th epoch marginal likelihood -25.6313012793\n",
      "400 -th epoch marginal likelihood -25.7023874574\n",
      "450 -th epoch marginal likelihood -25.7643476773\n",
      "500 -th epoch marginal likelihood -25.8176978448\n",
      "Done\n",
      "\n",
      "0003-th multiple probe search (EI) \n",
      "\n",
      "0004-th multiple probe search (EI) \n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood -39.0691700758\n",
      "50 -th epoch marginal likelihood -41.1071919843\n",
      "100 -th epoch marginal likelihood -41.9669646444\n",
      "150 -th epoch marginal likelihood -42.3527211324\n",
      "200 -th epoch marginal likelihood -42.5735324599\n",
      "250 -th epoch marginal likelihood -42.7349085808\n",
      "300 -th epoch marginal likelihood -42.8667364679\n",
      "350 -th epoch marginal likelihood -42.9759963516\n",
      "400 -th epoch marginal likelihood -43.064885703\n",
      "450 -th epoch marginal likelihood -43.1354953104\n",
      "500 -th epoch marginal likelihood -43.190388459\n",
      "Done\n",
      "\n",
      "0004-th multiple probe search (EI) \n",
      "\n",
      "0005-th multiple probe search (EI) \n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood -37.8936570042\n",
      "50 -th epoch marginal likelihood -45.0040337683\n",
      "100 -th epoch marginal likelihood -48.9605241174\n",
      "150 -th epoch marginal likelihood -51.1716265849\n",
      "200 -th epoch marginal likelihood -52.4532475555\n",
      "250 -th epoch marginal likelihood -53.2320141613\n",
      "300 -th epoch marginal likelihood -53.7373411494\n",
      "350 -th epoch marginal likelihood -54.0939679616\n",
      "400 -th epoch marginal likelihood -54.3692010432\n",
      "450 -th epoch marginal likelihood -54.5984628122\n",
      "500 -th epoch marginal likelihood -54.7996202126\n",
      "Done\n",
      "\n",
      "0005-th multiple probe search (EI) \n",
      "\n",
      "0006-th multiple probe search (EI) \n"
     ]
    }
   ],
   "source": [
    "# How to use the interactive mode \n",
    "simulator = simulator()\n",
    "\n",
    "# If you want to perform the initial random search before starting the Bayesian optimization, \n",
    "# the random sampling is performed by \n",
    "actions = policy.random_search(max_num_probes=1, num_search_each_probe=10, simulator=None)\n",
    "# Input: \n",
    "# max_num_probes: number of random search\n",
    "# num_search_each_probe: number of probes\n",
    "# simulator:  None !! \n",
    "# output: actions( numpy.array )\n",
    "t  = simulator(actions)\n",
    "\n",
    "# write the results into the policy\n",
    "policy.write(actions, t)\n",
    "\n",
    "actions = policy.random_search(max_num_probes=1, num_search_each_probe=10, simulator=None)\n",
    "t = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "\n",
    "# multiple probe Bayesian search\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, simulator=None, score='EI', \n",
    "                                                  interval=0, num_rand_basis=0)\n",
    "t = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, simulator=None, score='EI', \n",
    "                                                  interval=-1, num_rand_basis=0)\n",
    "\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, simulator=None, score='EI', \n",
    "                                                  interval=0, num_rand_basis=0)\n",
    "t = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, simulator=None, score='EI', \n",
    "                                                  interval=-1, num_rand_basis=0)\n",
    "\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, simulator=None, score='EI', \n",
    "                                                  interval=0, num_rand_basis=0)\n",
    "t = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, simulator=None, score='EI', \n",
    "                                                  interval=-1, num_rand_basis=0)\n",
    "\n",
    "# Input\n",
    "# max_num_probes: number of searching by Bayesian optimization\n",
    "# num_search_each_probe: number of probes\n",
    "# simulator: the class of simulator which is defined above\n",
    "# score: the type of aquision funciton. TS, EI and PI are available\n",
    "# interval: the timing for learning the hyper parameter. \n",
    "#               In this case, the hyper parameter is learned at each 20 steps\n",
    "#               If you set the negative value to interval, the hyper parameter learning is not performed \n",
    "#               If you set zero to interval, the hyper parameter learning is performed only at the first step\n",
    "# num_rand_basis: the number of basis function. If you choose 0,  ordinary Gaussian process runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "=policy.hi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
