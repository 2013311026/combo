{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import scipy\n",
    "import combo\n",
    "import os\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download():\n",
    "    if not os.path.exists('data/s5-210.csv'):\n",
    "\n",
    "        if not os.path.exists('data'):\n",
    "            os.mkdir('data')\n",
    "        \n",
    "        urllib.urlretrieve('http://www.tsudalab.org/files/s5-210.csv', 'data/s5-210.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    download()\n",
    "    A =  np.asarray( np.loadtxt('data/s5-210.csv',skiprows=1,delimiter=',') )\n",
    "    X = A[:,0:3]\n",
    "    t  = -A[:,3]\n",
    "    return X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data  \n",
    "# X is the N x d dimensional matrix. Each row of X denotes the d-dimensional feature vector of search candidate. \n",
    "# t is the N-dimensional vector that represents the corresponding negative energy of search candidates. \n",
    "# ( It is of course unknown in practice. )\n",
    "X, t = load_data()\n",
    " \n",
    "# Normalize the mean and standard deviation along the each column of X to 0 and 1, respectively\n",
    "X = combo.misc.centering( X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare the class for calling the simulator. \n",
    "# In this tutorial, we simply refer to the value of t. \n",
    "# If you want to apply combo to other problems, you have to customize this class. \n",
    "class simulator:\n",
    "    def __init__( self ):\n",
    "        _, self.t = load_data()\n",
    "    \n",
    "    def __call__( self, action ):\n",
    "        return self.t[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Design of policy\n",
    "\n",
    "# Declaring the policy by \n",
    "policy = combo.search.discrete.policy(test_X=X)\n",
    "# test_X is the set of candidates which is represented by numpy.array.\n",
    "# Each row vector represents the feature vector of the corresponding candidate\n",
    "\n",
    "# set the seed parameter \n",
    "policy.set_seed( 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interactive mode stars ... \n",
      " \n",
      "0001-th multiple probe search (random) \n",
      "\n",
      "current best f(x) = -0.980054 (best action = 4547) \n",
      "list of simulation results\n",
      "f(x)=-1.070602 (action = 15673)\n",
      "f(x)=-1.009056 (action = 9559)\n",
      "f(x)=-1.195844 (action = 16927)\n",
      "f(x)=-0.980054 (action = 4547)\n",
      "f(x)=-0.992820 (action = 2553)\n",
      "f(x)=-1.146676 (action = 13144)\n",
      "f(x)=-1.006255 (action = 10827)\n",
      "f(x)=-0.999862 (action = 1995)\n",
      "f(x)=-1.055445 (action = 10763)\n",
      "f(x)=-1.100970 (action = 16450)\n",
      "\n",
      "\n",
      "0002-th multiple probe search (random) \n",
      "\n",
      "current best f(x) = -0.980054 (best action = 4547) \n",
      "list of simulation results\n",
      "f(x)=-1.208666 (action = 13085)\n",
      "f(x)=-1.069404 (action = 15133)\n",
      "f(x)=-1.031642 (action = 1706)\n",
      "f(x)=-1.016702 (action = 2464)\n",
      "f(x)=-1.172569 (action = 17812)\n",
      "f(x)=-1.082219 (action = 16533)\n",
      "f(x)=-1.025272 (action = 1336)\n",
      "f(x)=-1.031761 (action = 10076)\n",
      "f(x)=-0.984972 (action = 8876)\n",
      "f(x)=-1.107730 (action = 15577)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood -22.8397384798\n",
      "50 -th epoch marginal likelihood -24.1776171399\n",
      "100 -th epoch marginal likelihood -24.8310182858\n",
      "150 -th epoch marginal likelihood -25.1541614865\n",
      "200 -th epoch marginal likelihood -25.334465628\n",
      "250 -th epoch marginal likelihood -25.4551550106\n",
      "300 -th epoch marginal likelihood -25.5500914536\n",
      "350 -th epoch marginal likelihood -25.6313012793\n",
      "400 -th epoch marginal likelihood -25.7023874574\n",
      "450 -th epoch marginal likelihood -25.7643476773\n",
      "500 -th epoch marginal likelihood -25.8176978448\n",
      "Done\n",
      "\n",
      "0003-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.965358 (best action = 7677) \n",
      "list of simulation results\n",
      "f(x)=-1.080313 (action = 8128)\n",
      "f(x)=-0.965358 (action = 7677)\n",
      "f(x)=-1.069888 (action = 6744)\n",
      "f(x)=-1.000745 (action = 5438)\n",
      "f(x)=-0.991714 (action = 5993)\n",
      "f(x)=-1.089947 (action = 11497)\n",
      "f(x)=-1.054229 (action = 1253)\n",
      "f(x)=-1.044660 (action = 4687)\n",
      "f(x)=-1.054012 (action = 5246)\n",
      "f(x)=-0.965678 (action = 5031)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood -30.6042738797\n",
      "50 -th epoch marginal likelihood -35.8323970997\n",
      "100 -th epoch marginal likelihood -38.5632285433\n",
      "150 -th epoch marginal likelihood -40.0195014495\n",
      "200 -th epoch marginal likelihood -40.8402155845\n",
      "250 -th epoch marginal likelihood -41.3330181381\n",
      "300 -th epoch marginal likelihood -41.6536564484\n",
      "350 -th epoch marginal likelihood -41.883012718\n",
      "400 -th epoch marginal likelihood -42.0631217907\n",
      "450 -th epoch marginal likelihood -42.2153702356\n",
      "500 -th epoch marginal likelihood -42.3501791876\n",
      "Done\n",
      "\n",
      "0004-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.963138 (best action = 7308) \n",
      "list of simulation results\n",
      "f(x)=-0.980979 (action = 4735)\n",
      "f(x)=-0.999359 (action = 7857)\n",
      "f(x)=-0.963138 (action = 7308)\n",
      "f(x)=-1.120441 (action = 2785)\n",
      "f(x)=-1.060749 (action = 5669)\n",
      "f(x)=-0.977188 (action = 10857)\n",
      "f(x)=-1.019301 (action = 11987)\n",
      "f(x)=-1.283628 (action = 12002)\n",
      "f(x)=-0.991675 (action = 5957)\n",
      "f(x)=-1.027484 (action = 5303)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood -27.8101674631\n",
      "50 -th epoch marginal likelihood -38.5151806586\n",
      "100 -th epoch marginal likelihood -44.3860399514\n",
      "150 -th epoch marginal likelihood -47.687639627\n",
      "200 -th epoch marginal likelihood -49.6338245999\n",
      "250 -th epoch marginal likelihood -50.8300879488\n",
      "300 -th epoch marginal likelihood -51.5973262888\n",
      "350 -th epoch marginal likelihood -52.1139626467\n",
      "400 -th epoch marginal likelihood -52.4824699563\n",
      "450 -th epoch marginal likelihood -52.7627945703\n",
      "500 -th epoch marginal likelihood -52.9902029595\n",
      "Done\n",
      "\n",
      "0005-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.959371 (best action = 6568) \n",
      "list of simulation results\n",
      "f(x)=-0.959371 (action = 6568)\n",
      "f(x)=-0.990530 (action = 5365)\n",
      "f(x)=-0.996815 (action = 8990)\n",
      "f(x)=-1.118381 (action = 2987)\n",
      "f(x)=-1.009032 (action = 1643)\n",
      "f(x)=-1.019266 (action = 11951)\n",
      "f(x)=-1.033086 (action = 8473)\n",
      "f(x)=-1.056302 (action = 11470)\n",
      "f(x)=-0.990425 (action = 333)\n",
      "f(x)=-1.124811 (action = 15021)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood -10.6051046856\n",
      "50 -th epoch marginal likelihood -32.3974384599\n",
      "100 -th epoch marginal likelihood -45.3712800209\n",
      "150 -th epoch marginal likelihood -53.1999146465\n",
      "200 -th epoch marginal likelihood -58.0999678524\n",
      "250 -th epoch marginal likelihood -61.26712643\n",
      "300 -th epoch marginal likelihood -63.373135687\n",
      "350 -th epoch marginal likelihood -64.8112173017\n",
      "400 -th epoch marginal likelihood -65.8199219863\n",
      "450 -th epoch marginal likelihood -66.5483225979\n",
      "500 -th epoch marginal likelihood -67.0917875955\n",
      "Done\n",
      "\n",
      "0006-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.959371 (best action = 6568) \n",
      "list of simulation results\n",
      "f(x)=-0.970388 (action = 6789)\n",
      "f(x)=-1.003224 (action = 3057)\n",
      "f(x)=-0.975826 (action = 6196)\n",
      "f(x)=-1.022587 (action = 6758)\n",
      "f(x)=-1.137064 (action = 3432)\n",
      "f(x)=-1.150921 (action = 8)\n",
      "f(x)=-2.497328 (action = 17945)\n",
      "f(x)=-2.497145 (action = 17981)\n",
      "f(x)=-0.983122 (action = 6695)\n",
      "f(x)=-1.189734 (action = 6011)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dd8b608a4aa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'history.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predictor.dump'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "# How to use the interactive mode \n",
    "simulator = simulator()\n",
    "\n",
    "''' 1st step (random sampling) '''\n",
    "actions = policy.random_search(max_num_probes=1, num_search_each_probe=10, simulator=None)\n",
    "t  = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "combo.search.utility.show_search_results(policy.history, 10)\n",
    "\n",
    "''' 2nd step (random sampling) '''\n",
    "actions = policy.random_search(max_num_probes=1, num_search_each_probe=10, simulator=None)\n",
    "t = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "combo.search.utility.show_search_results(policy.history, 10)\n",
    "\n",
    "''' 3rd step (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)   # experiment\n",
    "policy.write(actions, t) # record new observations\n",
    "combo.search.utility.show_search_results(policy.history, 10)  # describe search results\n",
    "\n",
    "predictor = policy.predictor\n",
    "training = policy.training\n",
    "\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      predictor=predictor, training=training,\n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)   # experiment\n",
    "policy.write(actions, t) # record new observations\n",
    "combo.search.utility.show_search_results(policy.history, 10)  # describe search results\n",
    "\n",
    "\n",
    "\n",
    "''' 4-th step (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)   # experiment\n",
    "policy.write(actions, t) # record new observations\n",
    "combo.search.utility.show_search_results(policy.history, 10)  # describe search results\n",
    "\n",
    "predictor = policy.predictor\n",
    "training = policy.training\n",
    "\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      predictor=predictor, training=training,\n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)   # experiment\n",
    "policy.write(actions, t) # record new observations\n",
    "combo.search.utility.show_search_results(policy.history, 10)  # describe search results\n",
    "\n",
    "\n",
    "''' save the result '''\n",
    "policy.predictor.save('predictor.dump')\n",
    "policy.training.save('training.npz')\n",
    "policy.history.save('history.npz')\n",
    "\n",
    "''' delete policy'''\n",
    "del policy\n",
    "\n",
    "policy = combo.search.discrete.policy(test_X=X)\n",
    "policy.load('history.npz')\n",
    "policy.load_predictor.load('predictor.dump')\n",
    "policy.load_training.load('training.npz')\n",
    "\n",
    "''' 5-th probe (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)   # experiment\n",
    "policy.write(actions, t) # record new observations\n",
    "combo.search.utility.show_search_results(policy.history, 10)  # describe search result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res=policy.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(res.fx[0:res.total_num_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
